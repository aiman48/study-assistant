
# ğŸ“š Study Assistant Chatbot

A study assistant chatbot built with **LangChain**, **Google Gemini** (LLM), and **Hugging Face embeddings**.
The assistant can answer study-related questions, maintain conversation memory, and present **structured output** in a clear format.
It includes an **excellent Streamlit UI** with chat history, memory, and export functionality.

---

## ğŸš€ Features

âœ… Uses **Gemini** as the main LLM
âœ… Uses **Hugging Face embeddings** + **Chroma** for conversation memory
âœ… Custom **prompt template** â†’ always returns structured JSON:

```json
{
  "answer": "...",
  "key_points": ["...", "..."],
  "follow_up_questions": ["...", "..."],
  "references": ["...", "..."]
}
```

âœ… **Streamlit UI** with:

* Chat window (like ChatGPT)
* Structured output sections (Answer, Key Points, Follow-ups, References)
* Sidebar memory viewer
* Export and clear conversation options

âœ… **Persistent memory** â€” conversations are saved with Chroma and JSON logs.

---

## ğŸ› ï¸ Tech Stack

* [LangChain](https://www.langchain.com/)
* [Google Gemini](https://ai.google.dev/)
* [Hugging Face Embeddings](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)
* [ChromaDB](https://www.trychroma.com/)
* [Streamlit](https://streamlit.io/)

---

## ğŸ“‚ Project Structure

```
study-assistant/
â”‚â”€â”€ app.py            # Streamlit UI
â”‚â”€â”€ chain.py          # LangChain pipeline (prompt + LLM + memory)
â”‚â”€â”€ models.py         # Gemini + Hugging Face embeddings setup
â”‚â”€â”€ db.py             # Conversation persistence (Chroma + JSON logs)
â”‚â”€â”€ .env              # API keys and model configs
â”‚â”€â”€ requirements.txt  # Dependencies
â”‚â”€â”€ README.md         # Documentation
```

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/aiman48/study-assistant.git
cd study-assistant-langchain
```

### 2ï¸âƒ£ Create virtual environment

```bash
python -m venv .venv
source .venv/bin/activate   # Mac/Linux
.venv\Scripts\activate      # Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Add API keys

Create a `.env` file in the root folder:

```ini
# Gemini API (Google AI Studio)
GOOGLE_API_KEY=your_gemini_api_key_here

# Hugging Face
HUGGINGFACEHUB_API_TOKEN=your_huggingface_token_here

# Model settings
HF_EMBED_MODEL=sentence-transformers/all-mpnet-base-v2
GEMINI_MODEL=gemini-1.5-flash
```

### 5ï¸âƒ£ Run the app

```bash
streamlit run app.py
```

---

## ğŸ® Usage

1. Open the Streamlit UI in your browser (link shown after running).

2. Type your study questions (e.g., *"Explain supervised learning"*)

3. The assistant will respond with:

   * ğŸ“– **Answer** (natural explanation)
   * ğŸ”‘ **Key Points** (bullet notes)
   * ğŸ¤” **Follow-up Questions**
   * ğŸ“š **References**

4. Sidebar shows memory of past chats.

5. Export or clear conversation anytime.

---

## ğŸ§  Example

**Question:**

> "Explain machine learning models."

**Structured Output:**

```json
{
  "answer": "Machine learning models are algorithms that learn patterns from data...",
  "key_points": [
    "Supervised, unsupervised, reinforcement learning",
    "Models include decision trees, neural networks, SVMs",
    "Used in predictions, classification, recommendations"
  ],
  "follow_up_questions": [
    "What is supervised learning?",
    "How are neural networks trained?"
  ],
  "references": [
    "https://scikit-learn.org/",
    "https://en.wikipedia.org/wiki/Machine_learning"
  ]
}
```

---

## ğŸ“Œ Requirements Checklist

âœ”ï¸ LangChain
âœ”ï¸ Gemini (LLM)
âœ”ï¸ Hugging Face embeddings
âœ”ï¸ Memory (Chroma)
âœ”ï¸ Prompt Template (structured JSON)
âœ”ï¸ Structured Output
âœ”ï¸ Messages (chat UI with history)
âœ”ï¸ Streamlit excellent UI

---
